{
  
    
        "post0": {
            "title": "Title",
            "content": "Transfer Learning (Machine Learning) . (Draft) . Introduction . Transfer learning allows us to use trained layers from other models and applying them to our models. We can save time and resources by not having to train large networks. . Objective . We want to classify the images in the CIFAR10 dataset. . Approach . Here we use the ResNet50 model for image classification. We add some fully connected layers to classify the learned features into ten categories. . 1. Import Libraries . import math import tensorflow as tf import matplotlib.pyplot as plt import numpy as np from tensorflow.keras import Model from tensorflow.keras import layers from tensorflow.keras.applications import ResNet50 . 2. Load the dataset . CIFAR10 dataset is readily accessible through keras. . (train_img, train_lbl), (test_img, test_lbl) = tf.keras.datasets.cifar10.load_data() . 3. Preprocess images . Pre-processing converts RGB to BGR, zero-centers each color channel with respect to the ImageNet dataset. . train_img = (train_img).astype(&#39;float32&#39;) test_img = (test_img).astype(&#39;float32&#39;) train_img = tf.keras.applications.resnet50.preprocess_input(train_img) test_img = tf.keras.applications.resnet50.preprocess_input(test_img) NUM_EPOCHS = 20 print(&#39;Test images: &#39;, test_img.shape) print(&#39;Train images: &#39;, train_img.shape) . Test images: (10000, 32, 32, 3) Train images: (50000, 32, 32, 3) . 4. Load ResNet50 model . Use weights from imagenet, do not include the top layers, and freeze each layer to not-trainable. We want to use the trained model as is with some modifications. . pre_trained_model = ResNet50(input_shape = (224, 224, 3), weights=&#39;imagenet&#39;, classes = 10, include_top = False) for layer in pre_trained_model.layers: layer.trainable = False . 5. Create model . Specify shape of images for input. | Upsample image size by 7x to match ResNet50 architecture. | Add the pre-trained model. | Flatten the output of the model. | Add a few dense layers to adapt the model to your dataset. Use the relu activation function. | Specify the output with 10 output categories and a softmax activation. | . inputs = tf.keras.layers.Input(shape=(32,32,3)) x = tf.keras.layers.UpSampling2D(size=(7,7))(inputs) x = (pre_trained_model)(x) x = layers.GlobalAveragePooling2D()(x) x = layers.Dense(1024, activation=&#39;relu&#39;)(x) x = layers.Dropout(0.2)(x) x = layers.Dense(512, activation=&#39;relu&#39;)(x) x = layers.Dense(10, activation=&#39;softmax&#39;)(x) tx_model = tf.keras.Model(inputs = inputs, outputs = x) . 6. Compile model . Use Stochastic Gradient Descent for optimization, sparse categorical crossentropy as the loss parameter, and accuracy as the metric. Then fit the model using the training images and labels. . tx_model.compile(optimizer=&#39;SGD&#39;, loss=&#39;sparse_categorical_crossentropy&#39;, metrics = [&#39;accuracy&#39;]) tx_model.summary() history = tx_model.fit(train_img, train_lbl, batch_size=256, epochs = NUM_EPOCHS, validation_data = (test_img, test_lbl), verbose = 1) . Model: &#34;model&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_2 (InputLayer) [(None, 32, 32, 3)] 0 up_sampling2d (UpSampling2D (None, 224, 224, 3) 0 ) resnet50 (Functional) (None, 7, 7, 2048) 23587712 global_average_pooling2d (G (None, 2048) 0 lobalAveragePooling2D) dense (Dense) (None, 1024) 2098176 dropout (Dropout) (None, 1024) 0 dense_1 (Dense) (None, 512) 524800 dense_2 (Dense) (None, 10) 5130 ================================================================= Total params: 26,215,818 Trainable params: 2,628,106 Non-trainable params: 23,587,712 _________________________________________________________________ Epoch 1/20 196/196 [==============================] - 883s 4s/step - loss: 1.1993 - accuracy: 0.5902 - val_loss: 0.9152 - val_accuracy: 0.6767 Epoch 2/20 196/196 [==============================] - 836s 4s/step - loss: 0.8363 - accuracy: 0.7133 - val_loss: 0.7589 - val_accuracy: 0.7373 Epoch 3/20 196/196 [==============================] - 781s 4s/step - loss: 0.7427 - accuracy: 0.7429 - val_loss: 0.6880 - val_accuracy: 0.7600 Epoch 4/20 7/196 [&gt;.............................] - ETA: 10:18 - loss: 0.7264 - accuracy: 0.7349 . 7. Plot results . Plot the response (accuracy and loss) by epochs for the training and validation sets. . acc=history.history[&#39;accuracy&#39;] val_acc=history.history[&#39;val_accuracy&#39;] loss=history.history[&#39;loss&#39;] val_loss=history.history[&#39;val_loss&#39;] epochs=range(len(acc)) plt.plot(epochs, acc, &#39;o-r&#39;, label=&#39;Training&#39;) plt.plot(epochs, val_acc, &#39;o--b&#39;, label=&#39;Test&#39;) plt.title(&#39;Accuracy: Training and Validation&#39;) plt.legend(loc=&quot;lower right&quot;) plt.figure() plt.plot(epochs, loss, &#39;o-r&#39;, label=&#39;Training&#39;) plt.plot(epochs, val_loss, &#39;o--b&#39;, label=&#39;Test&#39;) plt.title(&#39;Loss: Training and Validation&#39;) plt.legend(loc=&quot;upper right&quot;) .",
            "url": "https://joshisaumil.github.io/ml-blog/2022/02/07/transfer-learning.html",
            "relUrl": "/2022/02/07/transfer-learning.html",
            "date": " • Feb 7, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Getting started with Jupyter",
            "content": "Jupyter notebook . Jupyter Notebook is a web application for creating and sharing computational (code + notebooks + data) documents. JupyterLab is the next generation implementation of Jupyter notebooks.1 . Jupyter architecture consists of . a kernel (which executes code) | a client (the browser) | a notebook (contains code, metadata, contents, outputs) | a notebook server (saves and loads notebooks) | . Documentation: Jupyter . Setup . Create a virtual environment . python3 -m venv py3 . Activate a virtual environment . source py3/bin/activate . Install Jupyter Lab . pip install jupyterlab pip install ipykernel . Add kernel . ipython kernel install --user --name=py3 . Launch Jupyter Lab . jupyter-lab . To list installed kernels . jupyter kernelspec list . To uninstall kernels . jupyter kernelspec uninstall py3 . Footnotes . Project jupyter [Internet]. [cited 2022 Jan 24]. Available from: https://jupyter.org &#8617; . |",
            "url": "https://joshisaumil.github.io/ml-blog/markdown/2022/01/22/jupyter.html",
            "relUrl": "/markdown/2022/01/22/jupyter.html",
            "date": " • Jan 22, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Scheduling Cron Jobs with Crontab",
            "content": "Introduction . Setting up scheduled jobs in unix/mac is simple. . Here is a description of cron. . There are five steps to create a simple task. . Describe the task . Set up a bash script that describes the task. . In the terminal, change directory to a local folder and edit a new file. . cd ~/path/to/dir nano hello.sh . Add the following lines to the file, press control + X to save and exit. . now=$(date) echo &quot;Hello World, it&#39;s $now&quot; . Schedule the task . In the terminal, change directory to a local folder and edit a new file. . cd ~/path/to/dir nano cron . Add the following line to the file, press control + X to save and exit. . 31 16 * * * cd ~/path/to/dir/ &amp;&amp; bash ./hello.sh &gt;| hello.log . The cron task syntax is as follows: . (minute) (hour) (day of the month) (month) (day of the week) &lt;command&gt; . Specifying a * in place of each parameter defaults to all. The example above refers to a task that runs every day of every month at 4:31 pm local time. . Submit the task . In the terminal, type the following to submit the tasks in the cronjob file. . crontab cronjob . Verify that crontab was updated with the new task list. In the terminal, type the following to list the tasks. . crontab -l . Check results . Check the output result after the task has run. . In the terminal, type the following to see the output. . cat hello.log . Here is a sample output . Hello World, it&#39;s Wed Mar 31 16:31:00 MDT 2021 . There is a lot you can do with crontab. The above will hopefully help you get started. . Other useful resources: https://ole.michelsen.dk/blog/schedule-jobs-with-crontab-on-mac-osx https://opensource.com/article/17/11/how-use-cron-linux https://crontab.guru/ .",
            "url": "https://joshisaumil.github.io/ml-blog/markdown/2022/01/17/cron.html",
            "relUrl": "/markdown/2022/01/17/cron.html",
            "date": " • Jan 17, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Welcome",
            "content": "",
            "url": "https://joshisaumil.github.io/ml-blog/markdown/2022/01/15/welcome.html",
            "relUrl": "/markdown/2022/01/15/welcome.html",
            "date": " • Jan 15, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://joshisaumil.github.io/ml-blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "About . Linkedin Google Scholar .",
          "url": "https://joshisaumil.github.io/ml-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://joshisaumil.github.io/ml-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}