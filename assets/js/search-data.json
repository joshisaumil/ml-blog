{
  
    
        "post0": {
            "title": "Title",
            "content": "Transfer Learning (Machine Learning) . (Draft) . Introduction . Transfer learning allows us to use trained layers from other models and applying them to our models. We can save time and resources by not having to train large networks. . Objective . We want to classify the images in the CIFAR10 dataset. . Approach . Here we use the ResNet50 model for image classification. We add some fully connected layers to classify the learned features into ten categories. . 1. Import Libraries . import math import tensorflow as tf import matplotlib.pyplot as plt import numpy as np from tensorflow.keras import Model from tensorflow.keras import layers from tensorflow.keras.applications import ResNet50 . 2. Load the dataset . CIFAR10 dataset is readily accessible through keras. . (train_img, train_lbl), (test_img, test_lbl) = tf.keras.datasets.cifar10.load_data() . 3. Preprocess images . Pre-processing converts RGB to BGR, zero-centers each color channel with respect to the ImageNet dataset. . train_img = (train_img).astype(&#39;float32&#39;) test_img = (test_img).astype(&#39;float32&#39;) train_img = tf.keras.applications.resnet50.preprocess_input(train_img) test_img = tf.keras.applications.resnet50.preprocess_input(test_img) NUM_EPOCHS = 20 print(&#39;Test images: &#39;, test_img.shape) print(&#39;Train images: &#39;, train_img.shape) . Test images: (10000, 32, 32, 3) Train images: (50000, 32, 32, 3) . 4. Load ResNet50 model . Use weights from imagenet, do not include the top layers, and freeze each layer to not-trainable. We want to use the trained model as is with some modifications. . pre_trained_model = ResNet50(input_shape = (224, 224, 3), weights=&#39;imagenet&#39;, classes = 10, include_top = False) for layer in pre_trained_model.layers: layer.trainable = False . 5. Create model . Specify shape of images for input. | Upsample image size by 7x to match ResNet50 architecture. | Add the pre-trained model. | Flatten the output of the model. | Add a few dense layers to adapt the model to your dataset. Use the relu activation function. | Specify the output with 10 output categories and a softmax activation. | . inputs = tf.keras.layers.Input(shape=(32,32,3)) x = tf.keras.layers.UpSampling2D(size=(7,7))(inputs) x = (pre_trained_model)(x) x = layers.GlobalAveragePooling2D()(x) x = layers.Dense(1024, activation=&#39;relu&#39;)(x) x = layers.Dropout(0.2)(x) x = layers.Dense(512, activation=&#39;relu&#39;)(x) x = layers.Dense(10, activation=&#39;softmax&#39;)(x) tx_model = tf.keras.Model(inputs = inputs, outputs = x) . 6. Compile model . Use Stochastic Gradient Descent for optimization, sparse categorical crossentropy as the loss parameter, and accuracy as the metric. Then fit the model using the training images and labels. . tx_model.compile(optimizer=&#39;SGD&#39;, loss=&#39;sparse_categorical_crossentropy&#39;, metrics = [&#39;accuracy&#39;]) tx_model.summary() history = tx_model.fit(train_img, train_lbl, batch_size=256, epochs = NUM_EPOCHS, validation_data = (test_img, test_lbl), verbose = 1) . Model: &#34;model&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_2 (InputLayer) [(None, 32, 32, 3)] 0 up_sampling2d (UpSampling2D (None, 224, 224, 3) 0 ) resnet50 (Functional) (None, 7, 7, 2048) 23587712 global_average_pooling2d (G (None, 2048) 0 lobalAveragePooling2D) dense (Dense) (None, 1024) 2098176 dropout (Dropout) (None, 1024) 0 dense_1 (Dense) (None, 512) 524800 dense_2 (Dense) (None, 10) 5130 ================================================================= Total params: 26,215,818 Trainable params: 2,628,106 Non-trainable params: 23,587,712 _________________________________________________________________ Epoch 1/20 196/196 [==============================] - 883s 4s/step - loss: 1.1993 - accuracy: 0.5902 - val_loss: 0.9152 - val_accuracy: 0.6767 Epoch 2/20 196/196 [==============================] - 836s 4s/step - loss: 0.8363 - accuracy: 0.7133 - val_loss: 0.7589 - val_accuracy: 0.7373 Epoch 3/20 196/196 [==============================] - 781s 4s/step - loss: 0.7427 - accuracy: 0.7429 - val_loss: 0.6880 - val_accuracy: 0.7600 Epoch 4/20 7/196 [&gt;.............................] - ETA: 10:18 - loss: 0.7264 - accuracy: 0.7349 . 7. Plot results . Plot the response (accuracy and loss) by epochs for the training and validation sets. . acc=history.history[&#39;accuracy&#39;] val_acc=history.history[&#39;val_accuracy&#39;] loss=history.history[&#39;loss&#39;] val_loss=history.history[&#39;val_loss&#39;] epochs=range(len(acc)) plt.plot(epochs, acc, &#39;o-r&#39;, label=&#39;Training&#39;) plt.plot(epochs, val_acc, &#39;o--b&#39;, label=&#39;Test&#39;) plt.title(&#39;Accuracy: Training and Validation&#39;) plt.legend(loc=&quot;lower right&quot;) plt.figure() plt.plot(epochs, loss, &#39;o-r&#39;, label=&#39;Training&#39;) plt.plot(epochs, val_loss, &#39;o--b&#39;, label=&#39;Test&#39;) plt.title(&#39;Loss: Training and Validation&#39;) plt.legend(loc=&quot;upper right&quot;) .",
            "url": "https://joshisaumil.github.io/ml-blog/2022/02/07/transferlearning.html",
            "relUrl": "/2022/02/07/transferlearning.html",
            "date": " • Feb 7, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Jupyter",
            "content": "Getting started with Jupyter . Jupyter notebook . Jupyter Notebook is a web application for creating and sharing computational (code + notebooks + data) documents. JupyterLab is the next generation implementation of Jupyter notebooks.1 . Jupyter architecture consists of . a kernel (which executes code) | a client (the browser) | a notebook (contains code, metadata, contents, outputs) | a notebook server (saves and loads notebooks) | . Documentation: Jupyter . Setup . Create a virtual environment . python3 -m venv py3 . Activate a virtual environment . source py3/bin/activate . Install Jupyter Lab . pip install jupyterlab pip install ipykernel . Add kernel . ipython kernel install --user --name=py3 . Launch Jupyter Lab . jupyter-lab . To list installed kernels . jupyter kernelspec list . To uninstall kernels . jupyter kernelspec uninstall py3 . Footnotes . Project jupyter [Internet]. [cited 2022 Jan 24]. Available from: https://jupyter.org &#8617; . |",
            "url": "https://joshisaumil.github.io/ml-blog/2022/01/22/jupyter.html",
            "relUrl": "/2022/01/22/jupyter.html",
            "date": " • Jan 22, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Cron",
            "content": "Scheduling Cron Jobs with Crontab . Setting up scheduled jobs in unix/mac is simple. Here is a description of cron. . There are five steps to create a simple task. . Set up a bash script that describes the task. . In the terminal, change directory to a local folder and edit a new file. . cd ~/path/to/dir nano hello.sh . Add the following lines to the file, press control + X to save and exit. . now=$(date) echo &quot;Hello World, it&#39;s $now&quot; . | Create a cron file that schedules the task. . In the terminal, change directory to a local folder and edit a new file. . cd ~/path/to/dir nano cron . Add the following line to the file, press control + X to save and exit. . 31 16 * * * cd ~/path/to/dir/ &amp;&amp; bash ./hello.sh &gt;| hello.log . The cron task syntax is as follows: . (minute) (hour) (day of the month) (month) (day of the week) &lt;command&gt; . Specifying a * in place of each parameter defaults to all. The example above refers to a task that runs every day of every month at 4:31 pm local time. . | Submit the cron task. . In the terminal, type the following to submit the tasks in the cronjob file. . crontab cronjob . | Verify that the job was added to the task list. . In the terminal, type the following to list the tasks. . crontab -l . | Check the output result after the task has run. . In the terminal, type the following to see the output. . cat hello.log . Here is a sample output . Hello World, it&#39;s Wed Mar 31 16:31:00 MDT 2021 . | There is a lot you can do with crontab. The above will hopefully help you get started. . Other useful resources: https://ole.michelsen.dk/blog/schedule-jobs-with-crontab-on-mac-osx https://opensource.com/article/17/11/how-use-cron-linux https://crontab.guru/ .",
            "url": "https://joshisaumil.github.io/ml-blog/2022/01/17/cron.html",
            "relUrl": "/2022/01/17/cron.html",
            "date": " • Jan 17, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Welcome",
            "content": "Welcome . Hello, World. .",
            "url": "https://joshisaumil.github.io/ml-blog/2022/01/15/welcome.html",
            "relUrl": "/2022/01/15/welcome.html",
            "date": " • Jan 15, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Linkedin Google Scholar .",
          "url": "https://joshisaumil.github.io/ml-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://joshisaumil.github.io/ml-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}