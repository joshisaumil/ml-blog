{
  
    
        "post0": {
            "title": "Transfer Learning",
            "content": "Introduction . Transfer learning allows us to use trained layers from other models and applying them to our models. We can save time and resources by not having to train large networks. . Objective . We want to classify the images in the CIFAR10 dataset. It contains 60,000 images in 10 classes. . Approach . Here we use a well known pre-trained model (ResNet50) for image classification. On top of it, we add some fully connected layers to classify the learned features into ten categories. . 1.Import Libraries . import math import tensorflow as tf import matplotlib.pyplot as plt import numpy as np from tensorflow.keras import Model from tensorflow.keras import layers from tensorflow.keras.applications import ResNet50 . 2. Load the dataset . CIFAR10 dataset is readily accessible through keras. . (train_img, train_lbl), (test_img, test_lbl) = tf.keras.datasets.cifar10.load_data() . Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz 170500096/170498071 [==============================] - 12s 0us/step 170508288/170498071 [==============================] - 12s 0us/step . 3. Preprocess images . Pre-processing converts RGB to BGR, zero-centers each color channel with respect to the ImageNet dataset. . train_img = (train_img).astype(&#39;float32&#39;) test_img = (test_img).astype(&#39;float32&#39;) train_img = tf.keras.applications.resnet50.preprocess_input(train_img) test_img = tf.keras.applications.resnet50.preprocess_input(test_img) NUM_EPOCHS = 20 print(&#39;Test images: &#39;, test_img.shape) print(&#39;Train images: &#39;, train_img.shape) . Test images: (10000, 32, 32, 3) Train images: (50000, 32, 32, 3) . 4. Load ResNet50 model . Use weights from imagenet, do not include the top layers, and freeze each layer to not-trainable. We want to use the trained model as is with some modifications. . pre_trained_model = ResNet50(input_shape = (224, 224, 3), weights=&#39;imagenet&#39;, classes = 10, include_top = False) for layer in pre_trained_model.layers: layer.trainable = False . Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5 94773248/94765736 [==============================] - 0s 0us/step 94781440/94765736 [==============================] - 0s 0us/step . 5. Create model . Specify shape of images for input. | Upsample image size by 7x to match ResNet50 architecture. | Add the pre-trained model. | Flatten the output of the model. | Add a few dense layers to adapt the model to your dataset. Use the relu activation function. | Specify the output with 10 output categories and a softmax activation. | . inputs = tf.keras.layers.Input(shape=(32,32,3)) x = tf.keras.layers.UpSampling2D(size=(7,7))(inputs) x = (pre_trained_model)(x) x = layers.GlobalAveragePooling2D()(x) x = layers.Dense(1024, activation=&#39;relu&#39;)(x) x = layers.Dropout(0.2)(x) x = layers.Dense(512, activation=&#39;relu&#39;)(x) x = layers.Dense(10, activation=&#39;softmax&#39;)(x) tx_model = tf.keras.Model(inputs = inputs, outputs = x) . 6. Compile model . Use Stochastic Gradient Descent for optimization, sparse categorical crossentropy as the loss parameter, and accuracy as the metric. Then fit the model using the training images and labels. . tx_model.compile(optimizer=&#39;SGD&#39;, loss=&#39;sparse_categorical_crossentropy&#39;, metrics = [&#39;accuracy&#39;]) tx_model.summary() history = tx_model.fit(train_img, train_lbl, batch_size=256, epochs = NUM_EPOCHS, validation_data = (test_img, test_lbl), verbose = 1) . Model: &#34;model&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_2 (InputLayer) [(None, 32, 32, 3)] 0 up_sampling2d (UpSampling2D (None, 224, 224, 3) 0 ) resnet50 (Functional) (None, 7, 7, 2048) 23587712 global_average_pooling2d (G (None, 2048) 0 lobalAveragePooling2D) dense (Dense) (None, 1024) 2098176 dropout (Dropout) (None, 1024) 0 dense_1 (Dense) (None, 512) 524800 dense_2 (Dense) (None, 10) 5130 ================================================================= Total params: 26,215,818 Trainable params: 2,628,106 Non-trainable params: 23,587,712 _________________________________________________________________ Epoch 1/20 196/196 [==============================] - 90s 408ms/step - loss: 1.1992 - accuracy: 0.5885 - val_loss: 0.8620 - val_accuracy: 0.7040 Epoch 2/20 196/196 [==============================] - 79s 401ms/step - loss: 0.8300 - accuracy: 0.7135 - val_loss: 0.7340 - val_accuracy: 0.7436 Epoch 3/20 196/196 [==============================] - 79s 401ms/step - loss: 0.7389 - accuracy: 0.7425 - val_loss: 0.6749 - val_accuracy: 0.7644 Epoch 4/20 196/196 [==============================] - 79s 401ms/step - loss: 0.6850 - accuracy: 0.7631 - val_loss: 0.6593 - val_accuracy: 0.7700 Epoch 5/20 196/196 [==============================] - 79s 401ms/step - loss: 0.6479 - accuracy: 0.7757 - val_loss: 0.6292 - val_accuracy: 0.7794 Epoch 6/20 196/196 [==============================] - 79s 401ms/step - loss: 0.6174 - accuracy: 0.7851 - val_loss: 0.6192 - val_accuracy: 0.7809 Epoch 7/20 196/196 [==============================] - 79s 401ms/step - loss: 0.5981 - accuracy: 0.7910 - val_loss: 0.6085 - val_accuracy: 0.7889 Epoch 8/20 196/196 [==============================] - 78s 401ms/step - loss: 0.5761 - accuracy: 0.8007 - val_loss: 0.5799 - val_accuracy: 0.7978 Epoch 9/20 196/196 [==============================] - 79s 401ms/step - loss: 0.5592 - accuracy: 0.8061 - val_loss: 0.5734 - val_accuracy: 0.7996 Epoch 10/20 196/196 [==============================] - 78s 401ms/step - loss: 0.5449 - accuracy: 0.8113 - val_loss: 0.5621 - val_accuracy: 0.8046 Epoch 11/20 196/196 [==============================] - 78s 401ms/step - loss: 0.5319 - accuracy: 0.8142 - val_loss: 0.5693 - val_accuracy: 0.8010 Epoch 12/20 196/196 [==============================] - 79s 401ms/step - loss: 0.5186 - accuracy: 0.8193 - val_loss: 0.5430 - val_accuracy: 0.8121 Epoch 13/20 196/196 [==============================] - 78s 401ms/step - loss: 0.5085 - accuracy: 0.8208 - val_loss: 0.5291 - val_accuracy: 0.8145 Epoch 14/20 196/196 [==============================] - 78s 401ms/step - loss: 0.4980 - accuracy: 0.8261 - val_loss: 0.5256 - val_accuracy: 0.8197 Epoch 15/20 196/196 [==============================] - 79s 401ms/step - loss: 0.4877 - accuracy: 0.8309 - val_loss: 0.5555 - val_accuracy: 0.8056 Epoch 16/20 196/196 [==============================] - 79s 401ms/step - loss: 0.4759 - accuracy: 0.8342 - val_loss: 0.5302 - val_accuracy: 0.8123 Epoch 17/20 196/196 [==============================] - 78s 401ms/step - loss: 0.4670 - accuracy: 0.8378 - val_loss: 0.5361 - val_accuracy: 0.8112 Epoch 18/20 196/196 [==============================] - 78s 401ms/step - loss: 0.4585 - accuracy: 0.8411 - val_loss: 0.5069 - val_accuracy: 0.8228 Epoch 19/20 196/196 [==============================] - 78s 401ms/step - loss: 0.4513 - accuracy: 0.8433 - val_loss: 0.5061 - val_accuracy: 0.8254 Epoch 20/20 196/196 [==============================] - 79s 401ms/step - loss: 0.4446 - accuracy: 0.8441 - val_loss: 0.5036 - val_accuracy: 0.8217 . 7. Plot results . Plot the response (accuracy and loss) by epochs for the training and validation sets. . acc=history.history[&#39;accuracy&#39;] val_acc=history.history[&#39;val_accuracy&#39;] loss=history.history[&#39;loss&#39;] val_loss=history.history[&#39;val_loss&#39;] epochs=range(len(acc)) plt.plot(epochs, acc, &#39;o-r&#39;, label=&#39;Training&#39;) plt.plot(epochs, val_acc, &#39;o--b&#39;, label=&#39;Test&#39;) plt.title(&#39;Accuracy: Training and Validation&#39;) plt.legend(loc=&quot;lower right&quot;) plt.figure() plt.plot(epochs, loss, &#39;o-r&#39;, label=&#39;Training&#39;) plt.plot(epochs, val_loss, &#39;o--b&#39;, label=&#39;Test&#39;) plt.title(&#39;Loss: Training and Validation&#39;) plt.legend(loc=&quot;upper right&quot;) . &lt;matplotlib.legend.Legend at 0x7fb97e577ad0&gt; .",
            "url": "https://joshisaumil.github.io/ml-blog/jupyter/2022/02/07/transfer-learning.html",
            "relUrl": "/jupyter/2022/02/07/transfer-learning.html",
            "date": " • Feb 7, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Neural Networks",
            "content": "Introduction . Neural networks are very popular for image classification tasks. . Objective . We want to classify the images in the CIFAR10 dataset using a simple neural network. The dataset contains 60,000 images in 10 classes. . Approach . Here we use a basic 2-layer neural network. The 2-dimensional image is flattened and each pixel of the image is fed to the network. Two hidden layers with Rectified Linear Units (ReLUs) process the pixels and adjust the network weights using the Adam optimizer, allowing us to classify the learned features into ten categories. . 1.Import Libraries . import tensorflow as tf import matplotlib.pyplot as plt import numpy as np from tensorflow.keras.optimizers import RMSprop from tensorflow.keras import Model . 2. Load the dataset . CIFAR10 dataset is readily accessible through keras. . (train_img, train_lbl), (test_img, test_lbl) = tf.keras.datasets.cifar10.load_data() . 3. Scale images . Normalize or scale the images to [0 1] scale. . train_img, test_img = train_img/255.0, test_img/255.0 print(&#39;Size of training images: &#39;, train_img.shape) print(&#39;Size of test images: &#39;, test_img.shape) num_categories = len(np.unique(np.append(np.array(test_lbl),np.array(train_lbl)))) print(&#39;Number of categories: &#39;, num_categories) . Size of training images: (50000, 32, 32, 3) Size of test images: (10000, 32, 32, 3) Number of categories: 10 . 4. Create model . Flatten the 2-dimensional image. | Add a few dense layers (two in this case). Use the relu activation function. | Specify the output with 10 output categories and a softmax activation function. | Build the model. | Compile the model using the Adam optimizer and using a sparse categorical crossentropy loss function. Use accuracy as the metric for gauging performance. | Fit the model to the training data, and evaluare on the test images. | . simple_model = tf.keras.Sequential([ tf.keras.layers.Flatten(), tf.keras.layers.Dense(128, activation = tf.nn.relu), tf.keras.layers.Dense(32, activation = tf.nn.relu), tf.keras.layers.Dense(num_categories, activation = tf.nn.softmax) ]) simple_model.build([None, 32, 32, 3]) simple_model.summary() simple_model.compile(optimizer = tf.optimizers.Adam(), loss =&#39;sparse_categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) history = simple_model.fit(x = train_img, y = train_lbl, epochs = 20, validation_data = (test_img, test_lbl)) . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= flatten (Flatten) (None, 3072) 0 dense (Dense) (None, 128) 393344 dense_1 (Dense) (None, 32) 4128 dense_2 (Dense) (None, 10) 330 ================================================================= Total params: 397,802 Trainable params: 397,802 Non-trainable params: 0 _________________________________________________________________ Epoch 1/20 1563/1563 [==============================] - 7s 4ms/step - loss: 1.8978 - accuracy: 0.3128 - val_loss: 1.7527 - val_accuracy: 0.3615 Epoch 2/20 1563/1563 [==============================] - 4s 3ms/step - loss: 1.7215 - accuracy: 0.3803 - val_loss: 1.6533 - val_accuracy: 0.4121 Epoch 3/20 1563/1563 [==============================] - 4s 3ms/step - loss: 1.6530 - accuracy: 0.4074 - val_loss: 1.6116 - val_accuracy: 0.4206 Epoch 4/20 1563/1563 [==============================] - 4s 3ms/step - loss: 1.6042 - accuracy: 0.4255 - val_loss: 1.5824 - val_accuracy: 0.4325 Epoch 5/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.5680 - accuracy: 0.4395 - val_loss: 1.5571 - val_accuracy: 0.4450 Epoch 6/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.5435 - accuracy: 0.4483 - val_loss: 1.5224 - val_accuracy: 0.4578 Epoch 7/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.5194 - accuracy: 0.4552 - val_loss: 1.5374 - val_accuracy: 0.4537 Epoch 8/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.5038 - accuracy: 0.4639 - val_loss: 1.5850 - val_accuracy: 0.4403 Epoch 9/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4865 - accuracy: 0.4694 - val_loss: 1.5608 - val_accuracy: 0.4440 Epoch 10/20 1563/1563 [==============================] - 4s 3ms/step - loss: 1.4747 - accuracy: 0.4720 - val_loss: 1.4958 - val_accuracy: 0.4705 Epoch 11/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4607 - accuracy: 0.4767 - val_loss: 1.5169 - val_accuracy: 0.4597 Epoch 12/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4501 - accuracy: 0.4822 - val_loss: 1.4823 - val_accuracy: 0.4670 Epoch 13/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4418 - accuracy: 0.4828 - val_loss: 1.4812 - val_accuracy: 0.4767 Epoch 14/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4379 - accuracy: 0.4854 - val_loss: 1.5439 - val_accuracy: 0.4491 Epoch 15/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4307 - accuracy: 0.4872 - val_loss: 1.4729 - val_accuracy: 0.4766 Epoch 16/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4147 - accuracy: 0.4943 - val_loss: 1.4752 - val_accuracy: 0.4780 Epoch 17/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4088 - accuracy: 0.4953 - val_loss: 1.4627 - val_accuracy: 0.4843 Epoch 18/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4044 - accuracy: 0.4967 - val_loss: 1.4788 - val_accuracy: 0.4734 Epoch 19/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.3983 - accuracy: 0.5000 - val_loss: 1.4643 - val_accuracy: 0.4843 Epoch 20/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.3947 - accuracy: 0.5012 - val_loss: 1.4476 - val_accuracy: 0.4819 . 5. Plot results . Plot the response (accuracy and loss) by epochs for the training and validation sets. . acc=history.history[&#39;accuracy&#39;] val_acc=history.history[&#39;val_accuracy&#39;] loss=history.history[&#39;loss&#39;] val_loss=history.history[&#39;val_loss&#39;] epochs=range(len(acc)) plt.plot(epochs, acc, &#39;o-r&#39;, label=&#39;Training&#39;) plt.plot(epochs, val_acc, &#39;o--b&#39;, label=&#39;Validation&#39;) plt.title(&#39;Accuracy: Training and Validation&#39;) plt.legend(loc=&quot;lower right&quot;) plt.figure() plt.plot(epochs, loss, &#39;o-r&#39;, label=&#39;Training&#39;) plt.plot(epochs, val_loss, &#39;o--b&#39;, label=&#39;Validation&#39;) plt.title(&#39;Loss: Training and Validation&#39;) plt.legend(loc=&quot;upper right&quot;) . &lt;matplotlib.legend.Legend at 0x7f23046b79d0&gt; .",
            "url": "https://joshisaumil.github.io/ml-blog/jupyter/2022/02/05/neural-networks.html",
            "relUrl": "/jupyter/2022/02/05/neural-networks.html",
            "date": " • Feb 5, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Getting started with Jupyter",
            "content": "Jupyter notebook . Jupyter Notebook is a web application for creating and sharing computational (code + notebooks + data) documents. JupyterLab is the next generation implementation of Jupyter notebooks.1 . Jupyter architecture consists of . a kernel (which executes code) | a client (the browser) | a notebook (contains code, metadata, contents, outputs) | a notebook server (saves and loads notebooks) | . Documentation: Jupyter . Setup . Create a virtual environment . python3 -m venv py3 . Activate a virtual environment . source py3/bin/activate . Install Jupyter Lab . pip install jupyterlab pip install ipykernel . Add kernel . ipython kernel install --user --name=py3 . Launch Jupyter Lab . jupyter-lab . To list installed kernels . jupyter kernelspec list . To uninstall kernels . jupyter kernelspec uninstall py3 . Footnotes . Project jupyter [Internet]. [cited 2022 Jan 24]. Available from: https://jupyter.org &#8617; . |",
            "url": "https://joshisaumil.github.io/ml-blog/markdown/2022/01/22/jupyter.html",
            "relUrl": "/markdown/2022/01/22/jupyter.html",
            "date": " • Jan 22, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Scheduling Cron Jobs with Crontab",
            "content": "Introduction . Setting up scheduled jobs in unix/mac is simple. . Here is a description of cron. . There are five steps to create a simple task. . Describe the task . Set up a bash script that describes the task. . In the terminal, change directory to a local folder and edit a new file. . cd ~/path/to/dir nano hello.sh . Add the following lines to the file, press control + X to save and exit. . now=$(date) echo &quot;Hello World, it&#39;s $now&quot; . Schedule the task . In the terminal, change directory to a local folder and edit a new file. . cd ~/path/to/dir nano cron . Add the following line to the file, press control + X to save and exit. . 31 16 * * * cd ~/path/to/dir/ &amp;&amp; bash ./hello.sh &gt;| hello.log . The cron task syntax is as follows: . (minute) (hour) (day of the month) (month) (day of the week) &lt;command&gt; . Specifying a * in place of each parameter defaults to all. The example above refers to a task that runs every day of every month at 4:31 pm local time. . Submit the task . In the terminal, type the following to submit the tasks in the cronjob file. . crontab cronjob . Verify that crontab was updated with the new task list. In the terminal, type the following to list the tasks. . crontab -l . Check results . Check the output result after the task has run. . In the terminal, type the following to see the output. . cat hello.log . Here is a sample output . Hello World, it&#39;s Wed Mar 31 16:31:00 MDT 2021 . There is a lot you can do with crontab. The above will hopefully help you get started. . Other useful resources: https://ole.michelsen.dk/blog/schedule-jobs-with-crontab-on-mac-osx https://opensource.com/article/17/11/how-use-cron-linux https://crontab.guru/ .",
            "url": "https://joshisaumil.github.io/ml-blog/markdown/2022/01/17/cron.html",
            "relUrl": "/markdown/2022/01/17/cron.html",
            "date": " • Jan 17, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Welcome",
            "content": "",
            "url": "https://joshisaumil.github.io/ml-blog/markdown/2022/01/15/welcome.html",
            "relUrl": "/markdown/2022/01/15/welcome.html",
            "date": " • Jan 15, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "About . Linkedin Google Scholar .",
          "url": "https://joshisaumil.github.io/ml-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
      ,"page3": {
          "title": "Reference Links",
          "content": "Guides . Markdown Guide . Datasets . Google Dataset Search IBM Data Asset Exchange Tensorflow datasets . Blogs . Google AI blog Deep Mind blog Berkeley AI Research blog Papers with code IBM Research blog Microsoft AI blog Microsoft Research blog Sanyam Bhutani’s blog: Interviews Sebastian Ruder’s NLP/ML blog Lilian Weng’s blog . Concepts . Big O Notation Bagging and Boosting .",
          "url": "https://joshisaumil.github.io/ml-blog/references/",
          "relUrl": "/references/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://joshisaumil.github.io/ml-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}