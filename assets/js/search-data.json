{
  
    
        "post0": {
            "title": "Text Classification",
            "content": "Introduction . Neural networks make amazing text recognition systems. . Objective . We want to classify the emotions (positive, negative) in the IMDB database. . Approach . Here we use different models with embedding layers for text classification. The models are not perfect for this application, but serve as implementation examples. . Basic neural network model. | Recurrent neural network model. | 1D convolution neural network model. | . At the end, there is basic 1-layer or 2-layer fully connected network. The resulting features from the models are fed to this network. . 1. Import Libraries . import tensorflow as tf import matplotlib.pyplot as plt import numpy as np from tensorflow.keras.optimizers import RMSprop from tensorflow.keras import Model import tensorflow_datasets as tfds from tensorflow.keras.preprocessing.text import Tokenizer from tensorflow.keras.preprocessing.sequence import pad_sequences . 2. Load the dataset . dataset, info = tfds.load(&#39;imdb_reviews&#39;, with_info=True, as_supervised=True) train_dataset, test_dataset = dataset[&#39;train&#39;], dataset[&#39;test&#39;] . Downloading and preparing dataset imdb_reviews/plain_text/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0... Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteLDLFZ3/imdb_reviews-train.tfrecord Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteLDLFZ3/imdb_reviews-test.tfrecord Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteLDLFZ3/imdb_reviews-unsupervised.tfrecord . WARNING:absl:Dataset is using deprecated text encoder API which will be removed soon. Please use the plain_text version of the dataset and migrate to `tensorflow_text`. . Dataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data. . 3. Split into text and labels . train_text = [] train_label = [] test_text = [] test_label = [] for a, b in train_dataset: train_text.append(a.numpy().decode(&#39;utf8&#39;)) train_label.append(b.numpy()) for a, b in test_dataset: test_text.append(a.numpy().decode(&#39;utf8&#39;)) test_label.append(b.numpy()) train_labels = np.array(train_label) test_labels = np.array(test_label) . 4. Tokenize the training data . def max_len(list): # function to get the length of the longest sentence length = [len(l) for l in list] return max(length) oov_tok = &quot;&lt;OOV&gt;&quot; tokenizer = Tokenizer(oov_token=oov_tok) # create a tokenizer that will tokenize the text tokenizer.fit_on_texts(train_text) # fit the tokenizer on the training dataset index = tokenizer.word_index # get the dictionary of words in the text vocab_size = len(index) # get the size of the dictionary of words train_sequence = tokenizer.texts_to_sequences(train_text) # convert text to sequence of tokens maxlength = max_len(train_sequence) # get length of longest review train_pad = pad_sequences(train_sequence,maxlen=maxlength, truncating=&#39;post&#39;) # pad the sequence with 0s to make all reviews of same length test_sequence = tokenizer.texts_to_sequences(test_text) # convert text to sequence of tokens test_pad = pad_sequences(test_sequence,maxlen=maxlength) # pad the sequence with 0s to make all reviews of same length print(&#39;Unique words in vocabulary:&#39;, vocab_size) print(&#39;Length of longest sentence:&#39;, maxlength) print(&#39; n&#39;) print(&#39;Train:&#39;) print(&#39;Text: &#39;, train_text[1]) print(&#39;Sequence: &#39;, str(train_sequence[1])) print(&#39;Padded Sequence: &#39;, str(train_pad[1])) print(&#39; n&#39;) print(&#39;Test:&#39;) print(&#39;Text: &#39;, test_text[1]) print(&#39;Sequence: &#39;, str(test_sequence[1])) print(&#39;Padded Sequence: &#39;, str(test_pad[1])) . Unique words in vocabulary: 88583 Length of longest sentence: 2493 Train: Text: I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all. Sequence: [11, 26, 75, 571, 6, 805, 2354, 313, 106, 19, 12, 7, 629, 686, 6, 4, 2219, 5, 181, 584, 64, 1454, 110, 2263, 3, 3951, 21, 2, 34702, 3, 258, 41, 4677, 4, 174, 188, 21, 12, 4078, 11, 1578, 2354, 86, 2, 20, 14, 1907, 2, 112, 940, 14, 1811, 1340, 548, 3, 355, 181, 466, 6, 591, 19, 17, 55, 1817, 5, 49, 14, 4044, 96, 40, 136, 11, 972, 11, 201, 26, 1046, 171, 5, 2, 20, 19, 11, 294, 2, 2155, 5, 10, 3, 283, 41, 466, 6, 591, 5, 92, 203, 30570, 207, 99, 145, 4382, 16, 230, 332, 11, 2486, 384, 12, 20, 31, 30] Padded Sequence: [ 0 0 0 ... 20 31 30] Test: Text: A blackly comic tale of a down-trodden priest, Nazarin showcases the economy that Luis Bunuel was able to achieve in being able to tell a deeply humanist fable with a minimum of fuss. As an output from his Mexican era of film making, it was an invaluable talent to possess, with little money and extremely tight schedules. Nazarin, however, surpasses many of Bunuel&#39;s previous Mexican films in terms of the acting (Francisco Rabal is excellent), narrative and theme.&lt;br /&gt;&lt;br /&gt;The theme, interestingly, is something that was explored again in Viridiana, made three years later in Spain. It concerns the individual&#39;s struggle for humanity and altruism amongst a society that rejects any notion of virtue. Father Nazarin, however, is portrayed more sympathetically than Sister Viridiana. Whereas the latter seems to choose charity because she wishes to atone for her (perceived) sins, Nazarin&#39;s whole existence and reason for being seems to be to help others, whether they (or we) like it or not. The film&#39;s last scenes, in which he casts doubt on his behaviour and, in a split second, has to choose between the life he has been leading or the conventional life that is expected of a priest, are so emotional because they concern his moral integrity and we are never quite sure whether it remains intact or not.&lt;br /&gt;&lt;br /&gt;This is a remarkable film and I would urge anyone interested in classic cinema to seek it out. It is one of Bunuel&#39;s most moving films, and encapsulates many of his obsessions: frustrated desire, mad love, religious hypocrisy etc. In my view &#39;Nazarin&#39; is second only to &#39;The Exterminating Angel&#39;, in terms of his Mexican movies, and is certainly near the top of the list of Bunuel&#39;s total filmic output. Sequence: [4, 38367, 696, 784, 5, 4, 178, 23001, 2326, 1, 8758, 2, 8246, 13, 6079, 13997, 14, 500, 6, 2716, 9, 110, 500, 6, 374, 4, 1684, 23098, 9248, 17, 4, 4902, 5, 8632, 15, 33, 10593, 37, 25, 2661, 997, 5, 20, 229, 10, 14, 33, 16840, 674, 6, 6507, 17, 115, 276, 3, 574, 2697, 25343, 1, 188, 9477, 109, 5, 23384, 958, 2661, 106, 9, 1301, 5, 2, 114, 3711, 1, 7, 319, 1319, 3, 754, 8, 8, 2, 754, 5714, 7, 140, 13, 14, 4105, 172, 9, 1, 91, 287, 151, 301, 9, 5021, 10, 3278, 2, 19285, 1649, 16, 1944, 3, 75402, 2918, 4, 924, 13, 7107, 99, 4158, 5, 8514, 334, 1, 188, 7, 998, 51, 19860, 72, 797, 1, 3132, 2, 1566, 184, 6, 2259, 9942, 86, 57, 3081, 6, 27360, 16, 39, 8949, 7768, 1, 224, 2013, 3, 280, 16, 110, 184, 6, 28, 6, 336, 406, 724, 34, 40, 73, 38, 10, 40, 22, 2, 595, 234, 137, 9, 61, 27, 5978, 823, 21, 25, 5401, 3, 9, 4, 3250, 331, 46, 6, 2259, 198, 2, 111, 27, 46, 75, 969, 40, 2, 4013, 111, 13, 7, 871, 5, 4, 2326, 24, 36, 917, 86, 34, 4382, 25, 1510, 5036, 3, 73, 24, 113, 177, 250, 724, 10, 1287, 7026, 40, 22, 8, 8, 12, 7, 4, 1732, 20, 3, 11, 60, 4205, 257, 925, 9, 354, 435, 6, 2724, 10, 44, 10, 7, 29, 5, 23384, 89, 726, 106, 3, 31732, 109, 5, 25, 17053, 3565, 1758, 1166, 117, 1735, 11039, 522, 9, 59, 648, 1, 7, 331, 62, 6, 1063, 32424, 33634, 9, 1301, 5, 25, 2661, 100, 3, 7, 432, 748, 2, 348, 5, 2, 1026, 5, 23384, 962, 11360, 10593] Padded Sequence: [ 0 0 0 ... 962 11360 10593] . def plot_acc(history): acc=history.history[&#39;accuracy&#39;] val_acc=history.history[&#39;val_accuracy&#39;] loss=history.history[&#39;loss&#39;] val_loss=history.history[&#39;val_loss&#39;] epochs=range(len(acc)) plt.plot(epochs, acc, &#39;o-r&#39;, label=&#39;Training&#39;) plt.plot(epochs, val_acc, &#39;o--b&#39;, label=&#39;Validation&#39;) plt.title(&#39;Accuracy: Training and Validation&#39;) plt.legend(loc=&quot;lower right&quot;) plt.figure() plt.plot(epochs, loss, &#39;o-r&#39;, label=&#39;Training&#39;) plt.plot(epochs, val_loss, &#39;o--b&#39;, label=&#39;Validation&#39;) plt.title(&#39;Loss: Training and Validation&#39;) plt.legend(loc=&quot;upper right&quot;) . def predict(my_text, model): my_token = tokenizer.texts_to_sequences([my_text])[0] my_token_list = pad_sequences([my_token], maxlen=maxlength) return(my_text + &#39;:&#39; + str(model.predict(my_token_list))) . 4. Neural Network Model . model = tf.keras.Sequential([ tf.keras.layers.Embedding(vocab_size, 128, input_length=maxlength), # input_dim = size of vocabulary, output_dim = number of dimensions/embeddings, input_length = length of text tf.keras.layers.Flatten(), # or use tf.keras.layers.GlobalAveragePooling1D() tf.keras.layers.Dense(256, activation=&#39;relu&#39;), tf.keras.layers.Dropout(0.4), tf.keras.layers.Dense(1, activation=&#39;sigmoid&#39;) ]) model.compile(loss=&#39;binary_crossentropy&#39;,optimizer=&#39;adam&#39;,metrics=[&#39;accuracy&#39;]) model.summary() history = model.fit(train_pad, train_labels, epochs=10, validation_data=(test_pad, test_labels)) plot_acc(history) print(&#39; n&#39;) print(&#39;Prediction:&#39;) print(predict(&#39;Great and amazing movie!&#39;, model)) print(predict(&#39;Horribly bad movie.&#39;, model)) . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 2493, 128) 11338624 flatten (Flatten) (None, 319104) 0 dense (Dense) (None, 256) 81690880 dropout (Dropout) (None, 256) 0 dense_1 (Dense) (None, 1) 257 ================================================================= Total params: 93,029,761 Trainable params: 93,029,761 Non-trainable params: 0 _________________________________________________________________ Epoch 1/10 782/782 [==============================] - 18s 20ms/step - loss: 0.5837 - accuracy: 0.7156 - val_loss: 0.2866 - val_accuracy: 0.8787 Epoch 2/10 782/782 [==============================] - 16s 20ms/step - loss: 0.1236 - accuracy: 0.9561 - val_loss: 0.3239 - val_accuracy: 0.8760 Epoch 3/10 782/782 [==============================] - 16s 20ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.4066 - val_accuracy: 0.8771 Epoch 4/10 782/782 [==============================] - 16s 20ms/step - loss: 9.9207e-04 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.8774 Epoch 5/10 782/782 [==============================] - 17s 21ms/step - loss: 3.9690e-04 - accuracy: 1.0000 - val_loss: 0.4988 - val_accuracy: 0.8772 Epoch 6/10 782/782 [==============================] - 16s 21ms/step - loss: 1.8000e-04 - accuracy: 1.0000 - val_loss: 0.5261 - val_accuracy: 0.8785 Epoch 7/10 782/782 [==============================] - 16s 21ms/step - loss: 7.6387e-05 - accuracy: 1.0000 - val_loss: 0.5501 - val_accuracy: 0.8785 Epoch 8/10 782/782 [==============================] - 16s 20ms/step - loss: 6.0346e-05 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.8793 Epoch 9/10 782/782 [==============================] - 16s 20ms/step - loss: 0.0478 - accuracy: 0.9924 - val_loss: 0.8172 - val_accuracy: 0.8602 Epoch 10/10 782/782 [==============================] - 16s 20ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.6801 - val_accuracy: 0.8678 /n Prediction: Great and amazing movie!:[[0.9994312]] Horribly bad movie.:[[0.15351616]] . 5. Long Short Term Memory . model = tf.keras.Sequential([ tf.keras.layers.Embedding(vocab_size, 64), # embedding layer with input size = vocabulary size, and 64 embeddings tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences = True)), # Long Short Term Memory layer with 64 units, return seauences = True means many outputs tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)), tf.keras.layers.Dense(64, activation = &#39;relu&#39;), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(1, activation = &#39;sigmoid&#39;) ]) model.compile(loss=&#39;binary_crossentropy&#39;,optimizer=&#39;adam&#39;,metrics=[&#39;accuracy&#39;]) model.summary() history = model.fit(train_pad, train_labels, epochs=10, validation_data=(test_pad, test_labels)) plot_acc(history) print(&#39; n&#39;) print(&#39;Prediction:&#39;) print(predict(&#39;Great and amazing movie!&#39;, model)) print(predict(&#39;Horribly bad movie.&#39;, model)) . Model: &#34;sequential_1&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_1 (Embedding) (None, None, 64) 5669312 bidirectional (Bidirectiona (None, None, 128) 66048 l) bidirectional_1 (Bidirectio (None, 64) 41216 nal) dense_2 (Dense) (None, 64) 4160 dropout_1 (Dropout) (None, 64) 0 dense_3 (Dense) (None, 1) 65 ================================================================= Total params: 5,780,801 Trainable params: 5,780,801 Non-trainable params: 0 _________________________________________________________________ Epoch 1/10 782/782 [==============================] - 353s 443ms/step - loss: 0.4371 - accuracy: 0.7960 - val_loss: 0.3680 - val_accuracy: 0.8473 Epoch 2/10 782/782 [==============================] - 347s 443ms/step - loss: 0.2146 - accuracy: 0.9210 - val_loss: 0.4755 - val_accuracy: 0.8442 Epoch 3/10 782/782 [==============================] - 347s 443ms/step - loss: 0.1326 - accuracy: 0.9542 - val_loss: 0.4152 - val_accuracy: 0.8644 Epoch 4/10 782/782 [==============================] - 346s 443ms/step - loss: 0.0597 - accuracy: 0.9814 - val_loss: 0.5383 - val_accuracy: 0.8369 Epoch 5/10 782/782 [==============================] - 345s 441ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 0.6057 - val_accuracy: 0.8447 Epoch 6/10 782/782 [==============================] - 344s 441ms/step - loss: 0.0340 - accuracy: 0.9895 - val_loss: 0.5903 - val_accuracy: 0.8483 Epoch 7/10 782/782 [==============================] - 345s 441ms/step - loss: 0.0257 - accuracy: 0.9917 - val_loss: 0.6547 - val_accuracy: 0.8464 Epoch 8/10 782/782 [==============================] - 345s 441ms/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 0.6280 - val_accuracy: 0.8170 Epoch 9/10 782/782 [==============================] - 347s 443ms/step - loss: 0.0207 - accuracy: 0.9934 - val_loss: 0.7520 - val_accuracy: 0.8512 Epoch 10/10 782/782 [==============================] - 347s 443ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.7979 - val_accuracy: 0.8467 /n Prediction: Great and amazing movie!:[[0.6740849]] Horribly bad movie.:[[0.00324917]] . 6. Convolution model . model = tf.keras.Sequential([ tf.keras.layers.Embedding(vocab_size, 64, input_length=maxlength), tf.keras.layers.Conv1D(128, 5, activation=&#39;relu&#39;), tf.keras.layers.GlobalAveragePooling1D(), tf.keras.layers.Dense(512, activation=&#39;relu&#39;), tf.keras.layers.Dropout(0.4), tf.keras.layers.Dense(256, activation=&#39;relu&#39;), tf.keras.layers.Dropout(0.4), tf.keras.layers.Dense(1, activation=&#39;sigmoid&#39;) ]) model.compile(loss=&#39;binary_crossentropy&#39;,optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),metrics=[&#39;accuracy&#39;]) model.summary() history = model.fit(train_pad, train_labels, epochs=5, validation_data=(test_pad, test_labels)) plot_acc(history) print(&#39; n&#39;) print(&#39;Prediction:&#39;) print(predict(&#39;Great and amazing movie!&#39;, model)) print(predict(&#39;Horribly bad movie.&#39;, model)) . Model: &#34;sequential_2&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_2 (Embedding) (None, 2493, 64) 5669312 conv1d (Conv1D) (None, 2489, 128) 41088 global_average_pooling1d (G (None, 128) 0 lobalAveragePooling1D) dense_4 (Dense) (None, 512) 66048 dropout_2 (Dropout) (None, 512) 0 dense_5 (Dense) (None, 256) 131328 dropout_3 (Dropout) (None, 256) 0 dense_6 (Dense) (None, 1) 257 ================================================================= Total params: 5,908,033 Trainable params: 5,908,033 Non-trainable params: 0 _________________________________________________________________ Epoch 1/5 782/782 [==============================] - 19s 17ms/step - loss: 0.6911 - accuracy: 0.5218 - val_loss: 0.6668 - val_accuracy: 0.5908 Epoch 2/5 782/782 [==============================] - 13s 16ms/step - loss: 0.3912 - accuracy: 0.8325 - val_loss: 0.3102 - val_accuracy: 0.8739 Epoch 3/5 782/782 [==============================] - 13s 17ms/step - loss: 0.2260 - accuracy: 0.9146 - val_loss: 0.2869 - val_accuracy: 0.8855 Epoch 4/5 782/782 [==============================] - 13s 17ms/step - loss: 0.1677 - accuracy: 0.9405 - val_loss: 0.2888 - val_accuracy: 0.8882 Epoch 5/5 782/782 [==============================] - 13s 16ms/step - loss: 0.1264 - accuracy: 0.9581 - val_loss: 0.3026 - val_accuracy: 0.8880 /n Prediction: Great and amazing movie!:[[0.7612288]] Horribly bad movie.:[[0.36688864]] . 7. Experimenting on learning rates . model = tf.keras.Sequential([ tf.keras.layers.Embedding(vocab_size, 64, input_length=maxlength), tf.keras.layers.Conv1D(128, 5, activation=&#39;relu&#39;), tf.keras.layers.GlobalAveragePooling1D(), tf.keras.layers.Dense(512, activation=&#39;relu&#39;), tf.keras.layers.Dropout(0.4), tf.keras.layers.Dense(256, activation=&#39;relu&#39;), tf.keras.layers.Dropout(0.4), tf.keras.layers.Dense(1, activation=&#39;sigmoid&#39;) ]) lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch / 20)) model.compile(loss=&#39;binary_crossentropy&#39;,optimizer=tf.keras.optimizers.Adam(),metrics=[&#39;accuracy&#39;]) model.summary() history = model.fit(train_pad, train_labels, epochs=20, validation_data=(test_pad, test_labels), callbacks=[lr_schedule]) # plot learning rate vs. loss lrs = 1e-4 * (10 ** (np.arange(20) / 20)) plt.loglog(lrs, [abs(ele) for ele in history.history[&#39;loss&#39;]], &#39;o-&#39;) plt.axis([1e-4, 1e-2, 0, 1]) . Model: &#34;sequential_3&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_3 (Embedding) (None, 2493, 64) 5669312 conv1d_1 (Conv1D) (None, 2489, 128) 41088 global_average_pooling1d_1 (None, 128) 0 (GlobalAveragePooling1D) dense_7 (Dense) (None, 512) 66048 dropout_4 (Dropout) (None, 512) 0 dense_8 (Dense) (None, 256) 131328 dropout_5 (Dropout) (None, 256) 0 dense_9 (Dense) (None, 1) 257 ================================================================= Total params: 5,908,033 Trainable params: 5,908,033 Non-trainable params: 0 _________________________________________________________________ Epoch 1/20 782/782 [==============================] - 14s 17ms/step - loss: 0.6903 - accuracy: 0.5312 - val_loss: 0.6328 - val_accuracy: 0.7598 - lr: 1.0000e-04 Epoch 2/20 782/782 [==============================] - 13s 17ms/step - loss: 0.3457 - accuracy: 0.8627 - val_loss: 0.3016 - val_accuracy: 0.8779 - lr: 1.1220e-04 Epoch 3/20 782/782 [==============================] - 13s 17ms/step - loss: 0.2092 - accuracy: 0.9214 - val_loss: 0.2825 - val_accuracy: 0.8872 - lr: 1.2589e-04 Epoch 4/20 782/782 [==============================] - 13s 16ms/step - loss: 0.1460 - accuracy: 0.9498 - val_loss: 0.2910 - val_accuracy: 0.8873 - lr: 1.4125e-04 Epoch 5/20 782/782 [==============================] - 13s 17ms/step - loss: 0.0983 - accuracy: 0.9679 - val_loss: 0.3324 - val_accuracy: 0.8820 - lr: 1.5849e-04 Epoch 6/20 782/782 [==============================] - 13s 17ms/step - loss: 0.0635 - accuracy: 0.9812 - val_loss: 0.3969 - val_accuracy: 0.8765 - lr: 1.7783e-04 Epoch 7/20 782/782 [==============================] - 13s 17ms/step - loss: 0.0397 - accuracy: 0.9896 - val_loss: 0.4754 - val_accuracy: 0.8702 - lr: 1.9953e-04 Epoch 8/20 782/782 [==============================] - 13s 17ms/step - loss: 0.0258 - accuracy: 0.9939 - val_loss: 0.5465 - val_accuracy: 0.8648 - lr: 2.2387e-04 Epoch 9/20 782/782 [==============================] - 13s 16ms/step - loss: 0.0171 - accuracy: 0.9957 - val_loss: 0.6646 - val_accuracy: 0.8628 - lr: 2.5119e-04 Epoch 10/20 782/782 [==============================] - 13s 17ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.7212 - val_accuracy: 0.8562 - lr: 2.8184e-04 Epoch 11/20 782/782 [==============================] - 13s 17ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.7049 - val_accuracy: 0.8548 - lr: 3.1623e-04 Epoch 12/20 782/782 [==============================] - 13s 17ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.8591 - val_accuracy: 0.8524 - lr: 3.5481e-04 Epoch 13/20 782/782 [==============================] - 13s 17ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.8735 - val_accuracy: 0.8397 - lr: 3.9811e-04 Epoch 14/20 782/782 [==============================] - 13s 17ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.8633 - val_accuracy: 0.8418 - lr: 4.4668e-04 Epoch 15/20 782/782 [==============================] - 13s 17ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.8278 - val_accuracy: 0.8443 - lr: 5.0119e-04 Epoch 16/20 782/782 [==============================] - 13s 17ms/step - loss: 0.0142 - accuracy: 0.9948 - val_loss: 0.9816 - val_accuracy: 0.8416 - lr: 5.6234e-04 Epoch 17/20 782/782 [==============================] - 13s 17ms/step - loss: 0.0131 - accuracy: 0.9950 - val_loss: 0.8537 - val_accuracy: 0.8452 - lr: 6.3096e-04 Epoch 18/20 782/782 [==============================] - 13s 17ms/step - loss: 0.0140 - accuracy: 0.9948 - val_loss: 0.9517 - val_accuracy: 0.8458 - lr: 7.0795e-04 Epoch 19/20 782/782 [==============================] - 13s 17ms/step - loss: 0.0273 - accuracy: 0.9922 - val_loss: 0.8294 - val_accuracy: 0.8421 - lr: 7.9433e-04 Epoch 20/20 782/782 [==============================] - 13s 17ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.9868 - val_accuracy: 0.8316 - lr: 8.9125e-04 . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis. Invalid limit will be ignored. . (0.0001, 0.01, 0.008723800234883769, 1.0) . 8. Things to try to improve model . number of embeddings | number of LSTM units | Adam optimizer with custom learning rate | number of epochs | .",
            "url": "https://joshisaumil.github.io/ml-blog/jupyter/2022/02/13/text-classification.html",
            "relUrl": "/jupyter/2022/02/13/text-classification.html",
            "date": " • Feb 13, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Transfer Learning",
            "content": "Introduction . Transfer learning allows us to use trained layers from other models and apply them to our models. We can save time and resources by not having to train large networks. . Objective . We want to classify the images in the CIFAR10 dataset. It contains 60,000 images in 10 classes. . Approach . Here we use a well known pre-trained model (ResNet50) for image classification. On top of it, we add some fully connected layers to classify the learned features into ten categories. . 1.Import Libraries . import math import tensorflow as tf import matplotlib.pyplot as plt import numpy as np from tensorflow.keras import Model from tensorflow.keras import layers from tensorflow.keras.applications import ResNet50 . 2. Load the dataset . CIFAR10 dataset is readily accessible through keras. . (train_img, train_lbl), (test_img, test_lbl) = tf.keras.datasets.cifar10.load_data() . Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz 170500096/170498071 [==============================] - 12s 0us/step 170508288/170498071 [==============================] - 12s 0us/step . 3. Preprocess images . Pre-processing converts RGB to BGR, zero-centers each color channel with respect to the ImageNet dataset. . train_img = (train_img).astype(&#39;float32&#39;) test_img = (test_img).astype(&#39;float32&#39;) train_img = tf.keras.applications.resnet50.preprocess_input(train_img) test_img = tf.keras.applications.resnet50.preprocess_input(test_img) NUM_EPOCHS = 20 print(&#39;Test images: &#39;, test_img.shape) print(&#39;Train images: &#39;, train_img.shape) . Test images: (10000, 32, 32, 3) Train images: (50000, 32, 32, 3) . 4. Load ResNet50 model . Use weights from imagenet, do not include the top layers, and freeze each layer to not-trainable. We want to use the trained model as is with some modifications. . pre_trained_model = ResNet50(input_shape = (224, 224, 3), weights=&#39;imagenet&#39;, classes = 10, include_top = False) for layer in pre_trained_model.layers: layer.trainable = False . Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5 94773248/94765736 [==============================] - 0s 0us/step 94781440/94765736 [==============================] - 0s 0us/step . 5. Create model . Specify shape of images for input. | Upsample image size by 7x to match ResNet50 architecture. | Add the pre-trained model. | Flatten the output of the model. | Add a few dense layers to adapt the model to your dataset. Use the relu activation function. | Specify the output with 10 output categories and a softmax activation. | . inputs = tf.keras.layers.Input(shape=(32,32,3)) x = tf.keras.layers.UpSampling2D(size=(7,7))(inputs) x = (pre_trained_model)(x) x = layers.GlobalAveragePooling2D()(x) x = layers.Dense(1024, activation=&#39;relu&#39;)(x) x = layers.Dropout(0.2)(x) x = layers.Dense(512, activation=&#39;relu&#39;)(x) x = layers.Dense(10, activation=&#39;softmax&#39;)(x) tx_model = tf.keras.Model(inputs = inputs, outputs = x) . 6. Compile model . Use Stochastic Gradient Descent for optimization, sparse categorical crossentropy as the loss parameter, and accuracy as the metric. Then fit the model using the training images and labels. . tx_model.compile(optimizer=&#39;SGD&#39;, loss=&#39;sparse_categorical_crossentropy&#39;, metrics = [&#39;accuracy&#39;]) tx_model.summary() history = tx_model.fit(train_img, train_lbl, batch_size=256, epochs = NUM_EPOCHS, validation_data = (test_img, test_lbl), verbose = 1) . Model: &#34;model&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_2 (InputLayer) [(None, 32, 32, 3)] 0 up_sampling2d (UpSampling2D (None, 224, 224, 3) 0 ) resnet50 (Functional) (None, 7, 7, 2048) 23587712 global_average_pooling2d (G (None, 2048) 0 lobalAveragePooling2D) dense (Dense) (None, 1024) 2098176 dropout (Dropout) (None, 1024) 0 dense_1 (Dense) (None, 512) 524800 dense_2 (Dense) (None, 10) 5130 ================================================================= Total params: 26,215,818 Trainable params: 2,628,106 Non-trainable params: 23,587,712 _________________________________________________________________ Epoch 1/20 196/196 [==============================] - 90s 408ms/step - loss: 1.1992 - accuracy: 0.5885 - val_loss: 0.8620 - val_accuracy: 0.7040 Epoch 2/20 196/196 [==============================] - 79s 401ms/step - loss: 0.8300 - accuracy: 0.7135 - val_loss: 0.7340 - val_accuracy: 0.7436 Epoch 3/20 196/196 [==============================] - 79s 401ms/step - loss: 0.7389 - accuracy: 0.7425 - val_loss: 0.6749 - val_accuracy: 0.7644 Epoch 4/20 196/196 [==============================] - 79s 401ms/step - loss: 0.6850 - accuracy: 0.7631 - val_loss: 0.6593 - val_accuracy: 0.7700 Epoch 5/20 196/196 [==============================] - 79s 401ms/step - loss: 0.6479 - accuracy: 0.7757 - val_loss: 0.6292 - val_accuracy: 0.7794 Epoch 6/20 196/196 [==============================] - 79s 401ms/step - loss: 0.6174 - accuracy: 0.7851 - val_loss: 0.6192 - val_accuracy: 0.7809 Epoch 7/20 196/196 [==============================] - 79s 401ms/step - loss: 0.5981 - accuracy: 0.7910 - val_loss: 0.6085 - val_accuracy: 0.7889 Epoch 8/20 196/196 [==============================] - 78s 401ms/step - loss: 0.5761 - accuracy: 0.8007 - val_loss: 0.5799 - val_accuracy: 0.7978 Epoch 9/20 196/196 [==============================] - 79s 401ms/step - loss: 0.5592 - accuracy: 0.8061 - val_loss: 0.5734 - val_accuracy: 0.7996 Epoch 10/20 196/196 [==============================] - 78s 401ms/step - loss: 0.5449 - accuracy: 0.8113 - val_loss: 0.5621 - val_accuracy: 0.8046 Epoch 11/20 196/196 [==============================] - 78s 401ms/step - loss: 0.5319 - accuracy: 0.8142 - val_loss: 0.5693 - val_accuracy: 0.8010 Epoch 12/20 196/196 [==============================] - 79s 401ms/step - loss: 0.5186 - accuracy: 0.8193 - val_loss: 0.5430 - val_accuracy: 0.8121 Epoch 13/20 196/196 [==============================] - 78s 401ms/step - loss: 0.5085 - accuracy: 0.8208 - val_loss: 0.5291 - val_accuracy: 0.8145 Epoch 14/20 196/196 [==============================] - 78s 401ms/step - loss: 0.4980 - accuracy: 0.8261 - val_loss: 0.5256 - val_accuracy: 0.8197 Epoch 15/20 196/196 [==============================] - 79s 401ms/step - loss: 0.4877 - accuracy: 0.8309 - val_loss: 0.5555 - val_accuracy: 0.8056 Epoch 16/20 196/196 [==============================] - 79s 401ms/step - loss: 0.4759 - accuracy: 0.8342 - val_loss: 0.5302 - val_accuracy: 0.8123 Epoch 17/20 196/196 [==============================] - 78s 401ms/step - loss: 0.4670 - accuracy: 0.8378 - val_loss: 0.5361 - val_accuracy: 0.8112 Epoch 18/20 196/196 [==============================] - 78s 401ms/step - loss: 0.4585 - accuracy: 0.8411 - val_loss: 0.5069 - val_accuracy: 0.8228 Epoch 19/20 196/196 [==============================] - 78s 401ms/step - loss: 0.4513 - accuracy: 0.8433 - val_loss: 0.5061 - val_accuracy: 0.8254 Epoch 20/20 196/196 [==============================] - 79s 401ms/step - loss: 0.4446 - accuracy: 0.8441 - val_loss: 0.5036 - val_accuracy: 0.8217 . 7. Plot results . Plot the response (accuracy and loss) by epochs for the training and validation sets. . acc=history.history[&#39;accuracy&#39;] val_acc=history.history[&#39;val_accuracy&#39;] loss=history.history[&#39;loss&#39;] val_loss=history.history[&#39;val_loss&#39;] epochs=range(len(acc)) plt.plot(epochs, acc, &#39;o-r&#39;, label=&#39;Training&#39;) plt.plot(epochs, val_acc, &#39;o--b&#39;, label=&#39;Test&#39;) plt.title(&#39;Accuracy: Training and Validation&#39;) plt.legend(loc=&quot;lower right&quot;) plt.figure() plt.plot(epochs, loss, &#39;o-r&#39;, label=&#39;Training&#39;) plt.plot(epochs, val_loss, &#39;o--b&#39;, label=&#39;Test&#39;) plt.title(&#39;Loss: Training and Validation&#39;) plt.legend(loc=&quot;upper right&quot;) . &lt;matplotlib.legend.Legend at 0x7fb97e577ad0&gt; .",
            "url": "https://joshisaumil.github.io/ml-blog/jupyter/2022/02/07/transfer-learning.html",
            "relUrl": "/jupyter/2022/02/07/transfer-learning.html",
            "date": " • Feb 7, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Convolutional Neural Networks",
            "content": "Introduction . Convolutional Neural Networks (CNNs) are very popular for image classification tasks. They allow extracting abstract features from images and are better at learning than fully connected neural networks alone. . Objective . We want to classify the images in the CIFAR10 dataset using a simple convolutional neural network. The dataset contains 60,000 images in 10 classes. . Approach . Here we use a CNN for image classification. It has convolutional and max-pooling layers. Convolutional layers filter data, whereas max pooling layers extract the most useful features from this filtered data. . At the end, there is basic 2-layer neural network. The resulting features from the CNN/Pooling network are flattened and fed to this network. Two hidden layers with Rectified Linear Units (ReLUs) process the features and adjust the network weights using the Adam optimizer, allowing us to classify the learned features into ten categories. . 1.Import Libraries . import tensorflow as tf import matplotlib.pyplot as plt import numpy as np from tensorflow.keras.optimizers import RMSprop from tensorflow.keras import Model . 2. Load the dataset . CIFAR10 dataset is readily accessible through keras. . (train_img, train_lbl), (test_img, test_lbl) = tf.keras.datasets.cifar10.load_data() . 3. Scale images . Normalize or scale the images to [0 1] scale. . train_img, test_img = train_img/255.0, test_img/255.0 print(&#39;Size of training images: &#39;, train_img.shape) print(&#39;Size of test images: &#39;, test_img.shape) num_categories = len(np.unique(np.append(np.array(test_lbl),np.array(train_lbl)))) print(&#39;Number of categories: &#39;, num_categories) . Size of training images: (50000, 32, 32, 3) Size of test images: (10000, 32, 32, 3) Number of categories: 10 . 4. Create model . The model has 3 convolution + max pooling layers at the front. The size of the first layer is the size of the input images. Each convolution layer has a ReLU activation function. | Flatten the output from these layers. | Add a few dense layers (two in this case). Use the relu activation function. | Specify the output with 10 output categories and a softmax activation function. | Build the model. | Compile the model using the Adam optimizer and using a sparse categorical crossentropy loss function. Use accuracy as the metric for gauging performance. | Fit the model to the training data, and evaluate on the test images. | . # cnn model cnn_model = tf.keras.Sequential([ tf.keras.layers.Conv2D(32, (3,3), activation = &#39;relu&#39;, input_shape = (32, 32, 3)), tf.keras.layers.MaxPooling2D(2, 2), tf.keras.layers.Conv2D(32, (3,3), activation = &#39;relu&#39;), tf.keras.layers.MaxPooling2D(2, 2), tf.keras.layers.Conv2D(32, (3,3), activation = &#39;relu&#39;), tf.keras.layers.MaxPooling2D(2, 2), tf.keras.layers.Dropout(0.2), tf.keras.layers.Flatten(), tf.keras.layers.Dense(128, activation = tf.nn.relu), tf.keras.layers.Dense(64, activation = tf.nn.relu), tf.keras.layers.Dense(num_categories, activation = tf.nn.softmax) ]) cnn_model.summary() cnn_model.compile(optimizer = tf.optimizers.Adam(learning_rate = 1e-3), loss = tf.keras.losses.sparse_categorical_crossentropy, metrics = [&#39;accuracy&#39;]) history = cnn_model.fit(train_img, train_lbl, epochs = 20, validation_data = (test_img, test_lbl), verbose = 0) . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d (Conv2D) (None, 30, 30, 32) 896 max_pooling2d (MaxPooling2D (None, 15, 15, 32) 0 ) conv2d_1 (Conv2D) (None, 13, 13, 32) 9248 max_pooling2d_1 (MaxPooling (None, 6, 6, 32) 0 2D) conv2d_2 (Conv2D) (None, 4, 4, 32) 9248 max_pooling2d_2 (MaxPooling (None, 2, 2, 32) 0 2D) dropout (Dropout) (None, 2, 2, 32) 0 flatten (Flatten) (None, 128) 0 dense (Dense) (None, 128) 16512 dense_1 (Dense) (None, 64) 8256 dense_2 (Dense) (None, 10) 650 ================================================================= Total params: 44,810 Trainable params: 44,810 Non-trainable params: 0 _________________________________________________________________ . 5. Plot results . Plot the response (accuracy and loss) by epochs for the training and validation sets. . acc=history.history[&#39;accuracy&#39;] val_acc=history.history[&#39;val_accuracy&#39;] loss=history.history[&#39;loss&#39;] val_loss=history.history[&#39;val_loss&#39;] epochs=range(len(acc)) plt.plot(epochs, acc, &#39;o-r&#39;, label=&#39;Training&#39;) plt.plot(epochs, val_acc, &#39;o--b&#39;, label=&#39;Validation&#39;) plt.title(&#39;Accuracy: Training and Validation&#39;) plt.legend(loc=&quot;lower right&quot;) plt.figure() plt.plot(epochs, loss, &#39;o-r&#39;, label=&#39;Training&#39;) plt.plot(epochs, val_loss, &#39;o--b&#39;, label=&#39;Validation&#39;) plt.title(&#39;Loss: Training and Validation&#39;) plt.legend(loc=&quot;upper right&quot;) . &lt;matplotlib.legend.Legend at 0x7f95700667d0&gt; . 6. Streaming images from directory . Images can be streamed directly from a folder with training and validation data. . cat-dog/ training/ cat/ containing cat images | dog/ containing dog images | . | validation/ cat/ | dog/ | . | . | . from tensorflow.keras.preprocessing.image import ImageDataGenerator tr_gen = ImageDataGenerator( rescale=1./255, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode=&#39;nearest&#39;) val_gen = ImageDataGenerator(rescale=1/255) # stream training images from directory training = tr_gen.flow_from_directory(&#39;./cat-dog/training&#39;, target_size=(300, 300), batch_size=128, class_mode=&#39;binary&#39;) validation = val_gen.flow_from_directory(&#39;./cat-dog/validation&#39;, target_size=(300, 300), batch_size=128, class_mode=&#39;binary&#39;) history = model.fit_generator(training, steps_per_epoch=8, epochs=15, verbose=1, validation_data = validation, validation_steps=8) .",
            "url": "https://joshisaumil.github.io/ml-blog/jupyter/2022/02/06/convolutional-neural-networks.html",
            "relUrl": "/jupyter/2022/02/06/convolutional-neural-networks.html",
            "date": " • Feb 6, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Neural Networks",
            "content": "Introduction . Neural networks are very popular for image classification tasks. . Objective . We want to classify the images in the CIFAR10 dataset using a simple neural network. The dataset contains 60,000 images in 10 classes. . Approach . Here we use a basic 2-layer neural network. The 2-dimensional image is flattened and each pixel of the image is fed to the network. Two hidden layers with Rectified Linear Units (ReLUs) process the pixels and adjust the network weights using the Adam optimizer, allowing us to classify the learned features into ten categories. . 1.Import Libraries . import tensorflow as tf import matplotlib.pyplot as plt import numpy as np from tensorflow.keras.optimizers import RMSprop from tensorflow.keras import Model . 2. Load the dataset . CIFAR10 dataset is readily accessible through keras. . (train_img, train_lbl), (test_img, test_lbl) = tf.keras.datasets.cifar10.load_data() . 3. Scale images . Normalize or scale the images to [0 1] scale. . train_img, test_img = train_img/255.0, test_img/255.0 print(&#39;Size of training images: &#39;, train_img.shape) print(&#39;Size of test images: &#39;, test_img.shape) num_categories = len(np.unique(np.append(np.array(test_lbl),np.array(train_lbl)))) print(&#39;Number of categories: &#39;, num_categories) . Size of training images: (50000, 32, 32, 3) Size of test images: (10000, 32, 32, 3) Number of categories: 10 . 4. Create model . Flatten the 2-dimensional image. | Add a few dense layers (two in this case). Use the relu activation function. | Specify the output with 10 output categories and a softmax activation function. | Build the model. | Compile the model using the Adam optimizer and using a sparse categorical crossentropy loss function. Use accuracy as the metric for gauging performance. | Fit the model to the training data, and evaluare on the test images. | . simple_model = tf.keras.Sequential([ tf.keras.layers.Flatten(), tf.keras.layers.Dense(128, activation = tf.nn.relu), tf.keras.layers.Dense(32, activation = tf.nn.relu), tf.keras.layers.Dense(num_categories, activation = tf.nn.softmax) ]) simple_model.build([None, 32, 32, 3]) simple_model.summary() simple_model.compile(optimizer = tf.optimizers.Adam(), loss =&#39;sparse_categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) history = simple_model.fit(x = train_img, y = train_lbl, epochs = 20, validation_data = (test_img, test_lbl)) . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= flatten (Flatten) (None, 3072) 0 dense (Dense) (None, 128) 393344 dense_1 (Dense) (None, 32) 4128 dense_2 (Dense) (None, 10) 330 ================================================================= Total params: 397,802 Trainable params: 397,802 Non-trainable params: 0 _________________________________________________________________ Epoch 1/20 1563/1563 [==============================] - 7s 4ms/step - loss: 1.8978 - accuracy: 0.3128 - val_loss: 1.7527 - val_accuracy: 0.3615 Epoch 2/20 1563/1563 [==============================] - 4s 3ms/step - loss: 1.7215 - accuracy: 0.3803 - val_loss: 1.6533 - val_accuracy: 0.4121 Epoch 3/20 1563/1563 [==============================] - 4s 3ms/step - loss: 1.6530 - accuracy: 0.4074 - val_loss: 1.6116 - val_accuracy: 0.4206 Epoch 4/20 1563/1563 [==============================] - 4s 3ms/step - loss: 1.6042 - accuracy: 0.4255 - val_loss: 1.5824 - val_accuracy: 0.4325 Epoch 5/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.5680 - accuracy: 0.4395 - val_loss: 1.5571 - val_accuracy: 0.4450 Epoch 6/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.5435 - accuracy: 0.4483 - val_loss: 1.5224 - val_accuracy: 0.4578 Epoch 7/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.5194 - accuracy: 0.4552 - val_loss: 1.5374 - val_accuracy: 0.4537 Epoch 8/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.5038 - accuracy: 0.4639 - val_loss: 1.5850 - val_accuracy: 0.4403 Epoch 9/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4865 - accuracy: 0.4694 - val_loss: 1.5608 - val_accuracy: 0.4440 Epoch 10/20 1563/1563 [==============================] - 4s 3ms/step - loss: 1.4747 - accuracy: 0.4720 - val_loss: 1.4958 - val_accuracy: 0.4705 Epoch 11/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4607 - accuracy: 0.4767 - val_loss: 1.5169 - val_accuracy: 0.4597 Epoch 12/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4501 - accuracy: 0.4822 - val_loss: 1.4823 - val_accuracy: 0.4670 Epoch 13/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4418 - accuracy: 0.4828 - val_loss: 1.4812 - val_accuracy: 0.4767 Epoch 14/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4379 - accuracy: 0.4854 - val_loss: 1.5439 - val_accuracy: 0.4491 Epoch 15/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4307 - accuracy: 0.4872 - val_loss: 1.4729 - val_accuracy: 0.4766 Epoch 16/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4147 - accuracy: 0.4943 - val_loss: 1.4752 - val_accuracy: 0.4780 Epoch 17/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4088 - accuracy: 0.4953 - val_loss: 1.4627 - val_accuracy: 0.4843 Epoch 18/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.4044 - accuracy: 0.4967 - val_loss: 1.4788 - val_accuracy: 0.4734 Epoch 19/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.3983 - accuracy: 0.5000 - val_loss: 1.4643 - val_accuracy: 0.4843 Epoch 20/20 1563/1563 [==============================] - 4s 2ms/step - loss: 1.3947 - accuracy: 0.5012 - val_loss: 1.4476 - val_accuracy: 0.4819 . 5. Plot results . Plot the response (accuracy and loss) by epochs for the training and validation sets. . acc=history.history[&#39;accuracy&#39;] val_acc=history.history[&#39;val_accuracy&#39;] loss=history.history[&#39;loss&#39;] val_loss=history.history[&#39;val_loss&#39;] epochs=range(len(acc)) plt.plot(epochs, acc, &#39;o-r&#39;, label=&#39;Training&#39;) plt.plot(epochs, val_acc, &#39;o--b&#39;, label=&#39;Validation&#39;) plt.title(&#39;Accuracy: Training and Validation&#39;) plt.legend(loc=&quot;lower right&quot;) plt.figure() plt.plot(epochs, loss, &#39;o-r&#39;, label=&#39;Training&#39;) plt.plot(epochs, val_loss, &#39;o--b&#39;, label=&#39;Validation&#39;) plt.title(&#39;Loss: Training and Validation&#39;) plt.legend(loc=&quot;upper right&quot;) . &lt;matplotlib.legend.Legend at 0x7f23046b79d0&gt; .",
            "url": "https://joshisaumil.github.io/ml-blog/jupyter/2022/02/05/neural-networks.html",
            "relUrl": "/jupyter/2022/02/05/neural-networks.html",
            "date": " • Feb 5, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Getting started with Jupyter",
            "content": "Jupyter notebook . Jupyter Notebook is a web application for creating and sharing computational (code + notebooks + data) documents. JupyterLab is the next generation implementation of Jupyter notebooks.1 . Jupyter architecture consists of . a kernel (which executes code) | a client (the browser) | a notebook (contains code, metadata, contents, outputs) | a notebook server (saves and loads notebooks) | . Documentation: Jupyter . Setup . Create a virtual environment . python3 -m venv py3 . Activate a virtual environment . source py3/bin/activate . Install Jupyter Lab . pip install jupyterlab pip install ipykernel . Add kernel . ipython kernel install --user --name=py3 . Launch Jupyter Lab . jupyter-lab . To list installed kernels . jupyter kernelspec list . To uninstall kernels . jupyter kernelspec uninstall py3 . Footnotes . Project jupyter [Internet]. [cited 2022 Jan 24]. Available from: https://jupyter.org &#8617; . |",
            "url": "https://joshisaumil.github.io/ml-blog/markdown/2022/01/22/jupyter.html",
            "relUrl": "/markdown/2022/01/22/jupyter.html",
            "date": " • Jan 22, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Scheduling Cron Jobs with Crontab",
            "content": "Introduction . Setting up scheduled jobs in unix/mac is simple. . Here is a description of cron. . There are five steps to create a simple task. . Describe the task . Set up a bash script that describes the task. . In the terminal, change directory to a local folder and edit a new file. . cd ~/path/to/dir nano hello.sh . Add the following lines to the file, press control + X to save and exit. . now=$(date) echo &quot;Hello World, it&#39;s $now&quot; . Schedule the task . In the terminal, change directory to a local folder and edit a new file. . cd ~/path/to/dir nano cron . Add the following line to the file, press control + X to save and exit. . 31 16 * * * cd ~/path/to/dir/ &amp;&amp; bash ./hello.sh &gt;| hello.log . The cron task syntax is as follows: . (minute) (hour) (day of the month) (month) (day of the week) &lt;command&gt; . Specifying a * in place of each parameter defaults to all. The example above refers to a task that runs every day of every month at 4:31 pm local time. . Submit the task . In the terminal, type the following to submit the tasks in the cronjob file. . crontab cronjob . Verify that crontab was updated with the new task list. In the terminal, type the following to list the tasks. . crontab -l . Check results . Check the output result after the task has run. . In the terminal, type the following to see the output. . cat hello.log . Here is a sample output . Hello World, it&#39;s Wed Mar 31 16:31:00 MDT 2021 . There is a lot you can do with crontab. The above will hopefully help you get started. . Other useful resources: https://ole.michelsen.dk/blog/schedule-jobs-with-crontab-on-mac-osx https://opensource.com/article/17/11/how-use-cron-linux https://crontab.guru/ .",
            "url": "https://joshisaumil.github.io/ml-blog/markdown/2022/01/17/cron.html",
            "relUrl": "/markdown/2022/01/17/cron.html",
            "date": " • Jan 17, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "Welcome",
            "content": "",
            "url": "https://joshisaumil.github.io/ml-blog/markdown/2022/01/15/welcome.html",
            "relUrl": "/markdown/2022/01/15/welcome.html",
            "date": " • Jan 15, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "About . Linkedin Google Scholar .",
          "url": "https://joshisaumil.github.io/ml-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
      ,"page3": {
          "title": "Reference Links",
          "content": "Guides . Markdown Guide . Datasets . Google Dataset Search IBM Data Asset Exchange Tensorflow datasets . Blogs . Google AI blog Deep Mind blog Berkeley AI Research blog Papers with code IBM Research blog Microsoft AI blog Microsoft Research blog Sanyam Bhutani’s blog: Interviews Sebastian Ruder’s NLP/ML blog Lilian Weng’s blog . Concepts . Big O Notation Bagging and Boosting .",
          "url": "https://joshisaumil.github.io/ml-blog/references/",
          "relUrl": "/references/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://joshisaumil.github.io/ml-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}