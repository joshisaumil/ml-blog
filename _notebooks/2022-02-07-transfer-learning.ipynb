{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Transfer Learning (Machine Learning)\n",
        "_(Draft)_\n",
        "\n",
        "##Introduction\n",
        "[Transfer learning](https://en.wikipedia.org/wiki/Transfer_learning) allows us to use trained layers from other models and applying them to our models. We can save time and resources by not having to train large networks.\n",
        "\n",
        "##Objective\n",
        "We want to classify the images in the [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset. \n",
        "\n",
        "##Approach\n",
        "Here we use the ResNet50 model for image classification. We add some fully connected layers to classify the learned features into ten categories."
      ],
      "metadata": {
        "id": "5B3NetPaAv0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Import Libraries"
      ],
      "metadata": {
        "id": "5a04FXPz8n1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import ResNet50"
      ],
      "metadata": {
        "id": "yQTDOiwp8gML"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Load the dataset\n",
        "CIFAR10 dataset is readily accessible through keras."
      ],
      "metadata": {
        "id": "-8P1Lhd_80AA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_img, train_lbl), (test_img, test_lbl) = tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "DhaGfMZjRvP6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Preprocess images\n",
        "[Pre-processing](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/preprocess_input) converts RGB to BGR, zero-centers each color channel with respect to the ImageNet dataset."
      ],
      "metadata": {
        "id": "NNw_rYs286Ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_img = (train_img).astype('float32')\n",
        "test_img = (test_img).astype('float32')\n",
        "train_img = tf.keras.applications.resnet50.preprocess_input(train_img)\n",
        "test_img = tf.keras.applications.resnet50.preprocess_input(test_img)\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "print('Test images: ', test_img.shape)\n",
        "print('Train images: ', train_img.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWWzVE_787Rm",
        "outputId": "536e0bc1-f38f-477e-d4b2-aab02ad55946"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test images:  (10000, 32, 32, 3)\n",
            "Train images:  (50000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Load ResNet50 model\n",
        "Use weights from imagenet, do not include the top layers, and freeze each layer to not-trainable. We want to use the trained model as is with some modifications."
      ],
      "metadata": {
        "id": "0eCtq1LX90T2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get pre trained model\n",
        "pre_trained_model = ResNet50(input_shape = (224, 224, 3), weights='imagenet', classes = 10, include_top = False)\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "0b2lp9Sl9zIn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Create model\n",
        "\n",
        "- Specify shape of images for input.\n",
        "- Upsample image size by 7x to match ResNet50 architecture.\n",
        "- Add the pre-trained model.\n",
        "- Flatten the output of the model.\n",
        "- Add a few dense layers to adapt the model to your dataset. Use the relu activation function.\n",
        "- Specify the output with 10 output categories and a softmax activation."
      ],
      "metadata": {
        "id": "3yjnz11K97Fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(32,32,3))\n",
        "x = tf.keras.layers.UpSampling2D(size=(7,7))(inputs)\n",
        "x = (pre_trained_model)(x)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "x = layers.Dense(10, activation='softmax')(x)\n",
        "tx_model = tf.keras.Model(inputs = inputs, outputs = x)"
      ],
      "metadata": {
        "id": "iIU8okpR97RI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6. Compile model\n",
        "\n",
        "Use Stochastic Gradient Descent for optimization, sparse categorical crossentropy as the loss parameter, and accuracy as the metric. Then fit the model using the training images and labels."
      ],
      "metadata": {
        "id": "4iLY8SZq9-cI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tx_model.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "tx_model.summary()\n",
        "history = tx_model.fit(train_img, train_lbl, batch_size=256, epochs = NUM_EPOCHS, validation_data = (test_img, test_lbl), verbose = 1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdiIUfdK9-l3",
        "outputId": "0612cecb-404d-429b-e509-edb98025ffa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2D  (None, 224, 224, 3)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,215,818\n",
            "Trainable params: 2,628,106\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "196/196 [==============================] - 883s 4s/step - loss: 1.1993 - accuracy: 0.5902 - val_loss: 0.9152 - val_accuracy: 0.6767\n",
            "Epoch 2/20\n",
            "196/196 [==============================] - 836s 4s/step - loss: 0.8363 - accuracy: 0.7133 - val_loss: 0.7589 - val_accuracy: 0.7373\n",
            "Epoch 3/20\n",
            "196/196 [==============================] - 781s 4s/step - loss: 0.7427 - accuracy: 0.7429 - val_loss: 0.6880 - val_accuracy: 0.7600\n",
            "Epoch 4/20\n",
            "  7/196 [>.............................] - ETA: 10:18 - loss: 0.7264 - accuracy: 0.7349"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7. Plot results\n",
        "Plot the response (accuracy and loss) by epochs for the training and validation sets."
      ],
      "metadata": {
        "id": "sJbpNwG2-Aan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot accuracy and loss\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "epochs=range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'o-r', label='Training')\n",
        "plt.plot(epochs, val_acc, 'o--b', label='Test')\n",
        "plt.title('Accuracy: Training and Validation')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'o-r', label='Training')\n",
        "plt.plot(epochs, val_loss, 'o--b', label='Test')\n",
        "plt.title('Loss: Training and Validation')\n",
        "plt.legend(loc=\"upper right\")"
      ],
      "metadata": {
        "id": "n8lavkz7-Ake"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}